{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'distutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, TFBertForSequenceClassification\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n",
      "File \u001b[1;32mc:\\Users\\srees\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\__init__.py:30\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03mTop-level module of TensorFlow. By convention, we refer to this module as\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m`tf` instead of `tensorflow`, following the common practice of importing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mthis file with a file generated from [`api_template.__init__.py`](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/api_template.__init__.py)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order,protected-access,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdistutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_distutils\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_inspect\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'distutils'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  1208  100  1208    0     0   1908      0 --:--:-- --:--:-- --:--:--  1926\n",
      "\n",
      "  0  773M    0  321k    0     0   236k      0  0:55:48  0:00:01  0:55:47  236k\n",
      "  1  773M    1 10.2M    0     0  4471k      0  0:02:57  0:00:02  0:02:55 10.1M\n",
      "  2  773M    2 20.3M    0     0  5039k      0  0:02:37  0:00:04  0:02:33 7387k\n",
      "  3  773M    3 23.6M    0     0  5591k      0  0:02:21  0:00:04  0:02:17 8034k\n",
      "  4  773M    4 36.2M    0     0  6962k      0  0:01:53  0:00:05  0:01:48 9259k\n",
      "  5  773M    5 45.5M    0     0  7212k      0  0:01:49  0:00:06  0:01:43 9071k\n",
      "  7  773M    7 56.9M    0     0  7882k      0  0:01:40  0:00:07  0:01:33 9460k\n",
      "  8  773M    8 69.0M    0     0  8395k      0  0:01:34  0:00:08  0:01:26 11.3M\n",
      "  9  773M    9 73.1M    0     0  8018k      0  0:01:38  0:00:09  0:01:29  9.8M\n",
      " 11  773M   11 85.9M    0     0  8508k      0  0:01:33  0:00:10  0:01:23  9.9M\n",
      " 12  773M   12 97.3M    0     0  8743k      0  0:01:30  0:00:11  0:01:19 10.4M\n",
      " 13  773M   13  107M    0     0  8886k      0  0:01:29  0:00:12  0:01:17 10.1M\n",
      " 14  773M   14  114M    0     0  8812k      0  0:01:29  0:00:13  0:01:16 9528k\n",
      " 16  773M   16  123M    0     0  8735k      0  0:01:30  0:00:14  0:01:16  9.7M\n",
      " 17  773M   17  134M    0     0  8991k      0  0:01:28  0:00:15  0:01:13 9989k\n",
      " 19  773M   19  147M    0     0  9217k      0  0:01:25  0:00:16  0:01:09 10.0M\n",
      " 20  773M   20  155M    0     0  9184k      0  0:01:26  0:00:17  0:01:09 9919k\n",
      " 21  773M   21  165M    0     0  9147k      0  0:01:26  0:00:18  0:01:08  9.7M\n",
      " 22  773M   22  175M    0     0  9036k      0  0:01:27  0:00:19  0:01:08 9842k\n",
      " 23  773M   23  181M    0     0  9155k      0  0:01:26  0:00:20  0:01:06 9657k\n",
      " 24  773M   24  191M    0     0  9204k      0  0:01:26  0:00:21  0:01:05 9161k\n",
      " 26  773M   26  203M    0     0  9220k      0  0:01:25  0:00:22  0:01:03 9341k\n",
      " 27  773M   27  209M    0     0  9206k      0  0:01:25  0:00:23  0:01:02 9431k\n",
      " 28  773M   28  219M    0     0  9221k      0  0:01:25  0:00:24  0:01:01  9.8M\n",
      " 29  773M   29  228M    0     0  9183k      0  0:01:26  0:00:25  0:01:01 9294k\n",
      " 30  773M   30  238M    0     0  9279k      0  0:01:25  0:00:26  0:00:59 9602k\n",
      " 32  773M   32  250M    0     0  9383k      0  0:01:24  0:00:27  0:00:57  9.9M\n",
      " 33  773M   33  255M    0     0  9165k      0  0:01:26  0:00:28  0:00:58 8983k\n",
      " 33  773M   33  262M    0     0  9114k      0  0:01:26  0:00:29  0:00:57 8606k\n",
      " 35  773M   35  273M    0     0  9069k      0  0:01:27  0:00:30  0:00:57 8531k\n",
      " 36  773M   36  280M    0     0  9151k      0  0:01:26  0:00:31  0:00:55 8478k\n",
      " 37  773M   37  290M    0     0  9199k      0  0:01:26  0:00:32  0:00:54 8193k\n",
      " 38  773M   38  299M    0     0  9113k      0  0:01:26  0:00:33  0:00:53 8817k\n",
      " 39  773M   39  308M    0     0  9203k      0  0:01:26  0:00:34  0:00:52 9742k\n",
      " 40  773M   40  312M    0     0  9049k      0  0:01:27  0:00:35  0:00:52 8910k\n",
      " 41  773M   41  320M    0     0  9030k      0  0:01:27  0:00:36  0:00:51 8272k\n",
      " 43  773M   43  332M    0     0  9048k      0  0:01:27  0:00:37  0:00:50 8128k\n",
      " 44  773M   44  341M    0     0  9123k      0  0:01:26  0:00:38  0:00:48 9197k\n",
      " 45  773M   45  350M    0     0  9135k      0  0:01:26  0:00:39  0:00:47 8672k\n",
      " 46  773M   46  361M    0     0  9178k      0  0:01:26  0:00:40  0:00:46  9.8M\n",
      " 48  773M   48  371M    0     0  9075k      0  0:01:27  0:00:41  0:00:46 9365k\n",
      " 48  773M   48  377M    0     0  9123k      0  0:01:26  0:00:42  0:00:44 9718k\n",
      " 50  773M   50  388M    0     0  9167k      0  0:01:26  0:00:43  0:00:43 9504k\n",
      " 51  773M   51  395M    0     0  9139k      0  0:01:26  0:00:44  0:00:42 9166k\n",
      " 52  773M   52  407M    0     0  9197k      0  0:01:26  0:00:45  0:00:41 9351k\n",
      " 54  773M   54  418M    0     0  9238k      0  0:01:25  0:00:46  0:00:39 10.5M\n",
      " 55  773M   55  426M    0     0  9217k      0  0:01:25  0:00:47  0:00:38  9.7M\n",
      " 56  773M   56  437M    0     0  9232k      0  0:01:25  0:00:48  0:00:37 9783k\n",
      " 57  773M   57  448M    0     0  9218k      0  0:01:25  0:00:49  0:00:36 9870k\n",
      " 58  773M   58  455M    0     0  9258k      0  0:01:25  0:00:50  0:00:35 9809k\n",
      " 59  773M   59  462M    0     0  9157k      0  0:01:26  0:00:51  0:00:35 8469k\n",
      " 60  773M   60  470M    0     0  9196k      0  0:01:26  0:00:52  0:00:34 8992k\n",
      " 62  773M   62  482M    0     0  9260k      0  0:01:25  0:00:53  0:00:32 9541k\n",
      " 63  773M   63  488M    0     0  9208k      0  0:01:25  0:00:54  0:00:31 9092k\n",
      " 64  773M   64  498M    0     0  9216k      0  0:01:25  0:00:55  0:00:30 8793k\n",
      " 65  773M   65  508M    0     0  9127k      0  0:01:26  0:00:57  0:00:29 8831k\n",
      " 66  773M   66  511M    0     0  9133k      0  0:01:26  0:00:57  0:00:29 8476k\n",
      " 67  773M   67  518M    0     0  9110k      0  0:01:26  0:00:58  0:00:28 7500k\n",
      " 68  773M   68  529M    0     0  9124k      0  0:01:26  0:00:59  0:00:27 8217k\n",
      " 69  773M   69  540M    0     0  9141k      0  0:01:26  0:01:00  0:00:26 8351k\n",
      " 71  773M   71  550M    0     0  9193k      0  0:01:26  0:01:01  0:00:25  9.8M\n",
      " 71  773M   71  556M    0     0  9129k      0  0:01:26  0:01:02  0:00:24 9090k\n",
      " 73  773M   73  568M    0     0  9183k      0  0:01:26  0:01:03  0:00:23  9.8M\n",
      " 74  773M   74  578M    0     0  9212k      0  0:01:25  0:01:04  0:00:21 10.0M\n",
      " 76  773M   76  587M    0     0  9213k      0  0:01:25  0:01:05  0:00:20  9.8M\n",
      " 76  773M   76  594M    0     0  9183k      0  0:01:26  0:01:06  0:00:20 9065k\n",
      " 78  773M   78  604M    0     0  9139k      0  0:01:26  0:01:07  0:00:19 9245k\n",
      " 79  773M   79  613M    0     0  9185k      0  0:01:26  0:01:08  0:00:18 9207k\n",
      " 80  773M   80  622M    0     0  9185k      0  0:01:26  0:01:09  0:00:17 8830k\n",
      " 81  773M   81  628M    0     0  9152k      0  0:01:26  0:01:10  0:00:16 8353k\n",
      " 82  773M   82  635M    0     0  9120k      0  0:01:26  0:01:11  0:00:15 8287k\n",
      " 83  773M   83  646M    0     0  9147k      0  0:01:26  0:01:12  0:00:14 9270k\n",
      " 84  773M   84  654M    0     0  9135k      0  0:01:26  0:01:13  0:00:13 8439k\n",
      " 85  773M   85  659M    0     0  9064k      0  0:01:27  0:01:14  0:00:13 7448k\n",
      " 86  773M   86  668M    0     0  9066k      0  0:01:27  0:01:15  0:00:12 7915k\n",
      " 87  773M   87  679M    0     0  9114k      0  0:01:26  0:01:16  0:00:10 9029k\n",
      " 89  773M   89  688M    0     0  9115k      0  0:01:26  0:01:17  0:00:09 8662k\n",
      " 90  773M   90  698M    0     0  9124k      0  0:01:26  0:01:18  0:00:08 8964k\n",
      " 91  773M   91  708M    0     0  9141k      0  0:01:26  0:01:19  0:00:07 10.0M\n",
      " 91  773M   91  710M    0     0  9031k      0  0:01:27  0:01:20  0:00:07 8503k\n",
      " 92  773M   92  718M    0     0  9044k      0  0:01:27  0:01:21  0:00:06 7982k\n",
      " 94  773M   94  729M    0     0  9030k      0  0:01:27  0:01:22  0:00:05 7802k\n",
      " 95  773M   95  738M    0     0  9075k      0  0:01:27  0:01:23  0:00:04 8313k\n",
      " 96  773M   96  745M    0     0  9052k      0  0:01:27  0:01:24  0:00:03 7648k\n",
      " 97  773M   97  755M    0     0  9064k      0  0:01:27  0:01:25  0:00:02 9617k\n",
      " 99  773M   99  765M    0     0  9070k      0  0:01:27  0:01:26  0:00:01 9474k\n",
      "100  773M  100  773M    0     0  9099k      0  0:01:26  0:01:26 --:--:-- 10.1M\n"
     ]
    }
   ],
   "source": [
    "! curl -O -L \"https://huggingface.co/sree711/docClassification/resolve/main/bert_model.zip?download=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip bert_model.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert_model\")\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert_model\")\n",
    "\n",
    "model.load_weights(os.path.join(\"bert_model/model_weights.h5\"))\n",
    "label_encoder = joblib.load(\"bert_model/label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "def predictclass(input_words):\n",
    "    input_encodings = tokenizer(input_words, truncation=True, padding=True, max_length=max_length, return_tensors=\"tf\")\n",
    "\n",
    "    input_ids = input_encodings[\"input_ids\"]\n",
    "    token_type_ids = input_encodings[\"token_type_ids\"]\n",
    "    attention_mask = input_encodings[\"attention_mask\"]\n",
    "\n",
    "    predictions = model.predict([input_ids, token_type_ids, attention_mask])\n",
    "\n",
    "    probabilities = tf.nn.softmax(predictions.logits, axis=-1)\n",
    "    predicted_label = np.argmax(probabilities, axis=1)[0]\n",
    "    predicted_class = label_encoder.inverse_transform([predicted_label])[0]\n",
    "\n",
    "    print(f\"Sentence: {input_words}\")\n",
    "    print(f\"Predicted Class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words = \"patient name disease days admitted Sree cold Raghav lukemia\"\n",
    "\n",
    "predictclass(input_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
